tstat<-qt(1-alpha/2,n-2) # n -2 for model with intercept & slope
pe + c(-1.1) * (se * tstat)
alpha<-0.05
pe<-coef(summary(fit.simple))["amManual", "Estimate"]
se<-coef(summary(fit.simple))["amManual", "Std. Error"]
tstat<-qt(1-alpha/2,n-2)
n<-length(mtcars$mpg)
alpha<-0.05
pe<-coef(summary(fit.simple))["amManual", "Estimate"]
se<-coef(summary(fit.simple))["amManual", "Std. Error"]
tstat<-qt(1-alpha/2,n-2) # n -2 for model with intercept & slope
pe + c(-1.1) * (se * tstat)
pe + c(-1,1) * (se * tstat)
str(mtcars)
vif(fit.hvif)
vif(fit.all)
fit.all<-lm(mpg ~ ., data = mtcars)
vif(fit.all)
library(MASS)
library(xtable)
fit.optimal= lm(mpg ~ ., data=mtcars)
step = stepAIC(fit.optimal, direction="both")
step <-stepAIC(fit.optimal, direction="both")
step
(step <-stepAIC(fit.optimal, direction="both"))
fitAIC= lm(mpg ~ cyl  + hp+wt+am, data=mtcars)
sumAIC=summary(fitAIC)
round(fitAIC$coefficients,3)
p.value<-coef(summary(fit.simple))[2,4]
p.value
(p.value<-coef(summary(fit.simple))[2,4])
(p.value<-round(coef(summary(fit.simple))[2,4]),5)
fit.optimal= lm(mpg ~ ., data=mtcars)
(step <-stepAIC(fit.optimal, direction="both"))
fitAIC= lm(mpg ~ cyl  + hp+wt+am, data=mtcars)
sumAIC=summary(fitAIC)
round(fitAIC$coefficients,3)
fit.all<- lm(mpg ~ ., data=mtcars)
(step <-stepAIC(fit.all, direction="both"))
fit.optimal <- lm(mpg ~ cyl  + hp+wt+am, data=mtcars)
summary(fit.optimal)
(p.value<-coef(summary(fit.optimal))[2,4])
(p.value<-coef(summary(fit.optimal))[,4])
(p.value<-round(coef(summary(fit.optimal))[,4],3))
(p.value<-round(coef(summary(fit.optimal))[,4],5))
summary(fit.optimal)
summary(fit.optimal)$r
summary(fit.optimal)$r.squared
(p.value<-round(coef(summary(fit.optimal))[,4],5))
plot(fit.optimal)
plot(fit.optimal)
par(mfrow=c(2,2))
plot(fit.optimal)
summary(fit.optimal)$r.squared
round(fit.optimal$coefficients[6],3)
fit.optimal.2 <- lm(mpg ~ cyl+hp+wt, data=mtcars)
summary(fit.optimal2)
summary(fit.optimal2)$r.squared
(p.value<-round(coef(summary(fit.optimal2))[,4],5))
summary(fit.optimal.2)
summary(fit.optimal.2)$r.squared
(p.value<-round(coef(summary(fit.optimal.2))[,4],5))
(anova.NOam <- anova(fit.optimal.2, fit.optimal.1))
fit.optimal.1 <- lm(mpg ~ cyl+hp+wt+am, data=mtcars)
summary(fit.optimal.1)
summary(fit.optimal.1)$r.squared
(p.value<-round(coef(summary(fit.optimal.1))[,4],5))
(anova.NOam <- anova(fit.optimal.2, fit.optimal.1))
summary(fit.optimal.2)$r.squared
fit.optimal.3 <- lm(mpg ~ cyl+wt, data=mtcars)
summary(fit.optimal.3)
summary(fit.optimal.3)$r.squared
(p.value<-round(coef(summary(fit.optimal.3))[,4],5))
(p.value<-round(coef(summary(fit.optimal.2))[,4],5))
(p.value<-round(coef(summary(fit.optimal.1))[,4],5))
(p.value<-round(coef(summary(fit.optimal.3))[,4],5))
summary(fit.optimal.3)$r.squared
summary(fit.optimal.2)$r.squared
(anova.NOam <- anova(fit.optimal.2, fit.optimal.1))
(anova.NOam <- anova(fit.optimal.3, fit.optimal.2, fit.optima.l))
* The model explains 85.7% of the variation in mpg.
fit.optimal.3 <- lm(mpg ~ cyl+wt, data=mtcars)
summary(fit.optimal.3)
summary(fit.optimal.3)$r.squared
(p.value<-round(coef(summary(fit.optimal.3))[,4],5))
(anova.NOam <- anova(fit.optimal.3, fit.optimal.2, fit.optima.l))
(anova.NOam <- anova(fit.optimal.3, fit.optimal.2, fit.optimal.l))
fit.optimal.1 <- lm(mpg ~ cyl+hp+wt+am, data=mtcars)
summary(fit.optimal.1)
summary(fit.optimal.1)$r.squared
(p.value<-round(coef(summary(fit.optimal.1))[,4],5))
fit.optimal.2 <- lm(mpg ~ cyl+hp+wt, data=mtcars)
summary(fit.optimal.2)
summary(fit.optimal.2)$r.squared
(p.value<-round(coef(summary(fit.optimal.2))[,4],5))
fit.optimal.3 <- lm(mpg ~ cyl+wt, data=mtcars)
summary(fit.optimal.3)
summary(fit.optimal.3)$r.squared
(anova.NOam <- anova(fit.optimal.3, fit.optimal.2, fit.optimal.1))
(anova.NOam <- anova(fit.optimal.2, fit.optimal.1))
(anova.NOam <- round(anova(fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],3))
(anova.NOam <- round(anova(fit.optimal.3, fit.optimal.1)$"Pr(>F)"[2],3))
(anova.NOam <- round(anova(fit.optimal.3, fit.optimal.2)$"Pr(>F)"[2],3))
(anova.NOam <- round(anova(fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],3))
(anova.NOam <- anova(fit.optimal.3, fit.optimal.2, fit.optimal.1))
rstandard(fit.optimal.1)
plot(fit.optimal.1, which=3)
par(mfrow=c(1,1))
plot(fit.optimal.1, which=3)
par(mfrow=c(2,2))
plot(fit.optimal.1)
rstudent(fit.optimal.1)
cooks.distance(fit.optimal.1)
(summary(fit.simple)$r.squared)
(p.value<-coef(summary(fit.simple))[2,4])
step <-stepAIC(fit.all, direction="both")
(summary(fit.simple)$r.squared)
round(fit.simple$coefficients[2],3)
(anova.simple <- anova(fit.optimal.3, fit.optimal.2, fit.optimal.1,fit.simple)
)
(anova.simple <- anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1))
(anova.NOam <- round(anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],3))
(anova.NOam <- round(anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],6))
(anova.NOam <- round(anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],10))
(anova.NOam <- round(anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],9))
(anova.NOam <- round(anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2],7))
(anova.NOam <- anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2]))
(anova.NOam <- anova(fit.simple,fit.optimal.3, fit.optimal.2, fit.optimal.1)$"Pr(>F)"[2])
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
install.packages("segmentationOriginal")
install.packages("caret")
install.packages("pgmm")
install.packages("rpart")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
head(segmentationOriginal)
names(segmentationOriginal)
inTrain <-createDataPartition(y=segmentationOriginal$Case, p=0.75, ;list=FALSE)
inTrain <-createDataPartition(y=segmentationOriginal$Case, p=0.75, list=FALSE)
training <-segmentationOriginal(inTrain)
training <-segmentationOriginal[inTrain,]
testing <-segmentationOriginal[-inTrain,]
set.seed(125)
segmentationOriginal[,2]
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class~.,data=training,method="rpart")
model$finalModel
fancyRpartPlot(model$finalModel)
install.packages(fancyRpartPlot)
install.packages("fancyRpartPlot")
fancyRpartPlot(model$finalModel)
install.packages("fancyRpartPlot")
library(RColorBrewer)
library(rattle)
install.packages("rattle")
fancyRpartPlot(model$finalModel)
library(rattle)
fancyRpartPlot(model$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(model$finalModel)
fancyRpartPlot(model$finalModel)
par(mar = rep(2, 4))
fancyRpartPlot(model$finalModel)
rpart.plot(model)
library(rpart.plot)
rpart.plot(model)
rpart.plot(model$finalModel)
library(rpart.plot)
fancyRpartPlot(model$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
model<-rpart(Area ~., data = olive)
model
predict(model,newdata)
newdata = as.data.frame(t(colMeans(olive)))
predict(model,newdata)
model<-train(Area.~,data=olive,method=rpart())
model<-train(Area.~,data=olive,method=rpart
)
model<-train(Area~.,data=olive,method=rpart)
predict(model,newdata)
model<-train(Area~.,data=olive,method="rpart")
predict(model,newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
fit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, method="glm", family="binomial")
predictTrainSA <- predict(fit)
missClass(trainSA$chd,predictTrainSA)
install.packages("tree")
predictTrainSA <- predict(fit)
missClass(trainSA$chd,predictTrainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTrainSA <- predict(fit)
missClass(trainSA$chd,predictTrainSA)
data(vowel.train)
data(vowel.test)
vowel.test$y=as.factor(vowel.test$y)
vowel.train$y=as.factor(vowel.train$y)
set.seed(33833)
modRF<-train(y~., data=vowel.train, method="rf")
modRF<-train(y~., data=vowel.train, method="rf")
res<- predict(modelRF,vowel.test)
res<- predict(modRF,vowel.test)
varImp(modRF)
(modRF=randomForest(classe~.,data=training,importance=TRUE))
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(corrplot)
set.seed(12345)
training<- read.csv("E:/COURSERA/MACHINE LEARNING/WEEK-4/project/pml-training.csv",na.strings=c("NA","#DIV/0!",""))
testing<- read.csv("E:/COURSERA/MACHINE LEARNING/WEEK-4/project/pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
trainingCols<-colnames(training)
testingCols<-colnames(testing)
all.equal(trainingCols[1:length(trainingCols)-1], testingCols[1:length(testingCols)-1])
NAS    <- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[, NAS==FALSE]
testing  <- testing[, NAS==FALSE]
dim(training); dim(testing)
training  <- training[, -c(1:7)]
testing   <- testing[, -c(1:7)]
dim(training); dim(testing)
nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[,nzv$nzv==FALSE]
nzv<- nearZeroVar(testing,saveMetrics=TRUE)
testing <- testing[,nzv$nzv==FALSE]
dim(training); dim(testing)
(modRF=randomForest(classe~.,data=training,importance=TRUE))
predictionRF_FINAL <- predict(modRF, newdata=testing, type = "class")
cmRF <- confusionMatrix(predictionRF_FINAL, crossValidation$classe)
cmRF
cmRF <- confusionMatrix(predictionRF_FINAL, testing$problem_id)
predictRF_FINAL
predictionRF_FINAL <- predict(modRF, newdata=testing, type = "class")
predictionRF_FINAL
confusionMatrx(predictionRF_FINAL,testing$problem_id)
confusionMatrix(predictionRF_FINAL,testing$problem_id)
testing$problem_id=as.factor(testing$problem_id)
confusionMatrix(predictionRF_FINAL,testing$problem_id)
str(testing)
str(training)
testing$problem_id
predictionRF_FINAL
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(corrplot)
training<- read.csv("E:/COURSERA/MACHINE LEARNING/WEEK-4/project/pml-training.csv",na.strings=c("NA","#DIV/0!",""))
testing<- read.csv("E:/COURSERA/MACHINE LEARNING/WEEK-4/project/pml-testing.csv",na.strings=c("NA","#DIV/0!",""))
trainingCols<-colnames(training)
testingCols<-colnames(testing)
all.equal(trainingCols[1:length(trainingCols)-1], testingCols[1:length(testingCols)-1])
NAS<- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[, NAS==FALSE]
testing  <- testing[, NAS==FALSE]
dim(training); dim(testing)
training  <- training[, -c(1:7)]
testing   <- testing[, -c(1:7)]
dim(training); dim(testing)
nzv <- nearZeroVar(training, saveMetrics=TRUE)
training <- training[,nzv$nzv==FALSE]
nzv<- nearZeroVar(testing,saveMetrics=TRUE)
testing <- testing[,nzv$nzv==FALSE]
dim(training); dim(testing)
cor_jnk=cor(training, use="complete.obs")
cor_jnk=cor(training)
str(training)
str(training[,-53])
cor_jnk=cor(training[ ,-53])
cor_jnk
dim(training)
dim(cor_jnk)
corrplot(cor_jnk, order="AOE", method="circle", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
addCoef.col="black", addCoefasPercent = TRUE,
p.mat = 1-abs(cor_jnk), sig.level=0.50, insig = "blank")
corrplot(cor_jnk, order="AOE", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
addCoef.col="black", addCoefasPercent = TRUE,
p.mat = 1-abs(cor_jnk), sig.level=0.50, insig = "blank")
corrplot(cor_jnk, order="AOE", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
addCoef.col="black",
p.mat = 1-abs(cor_jnk), sig.level=0.50, insig = "blank")
corrplot(cor_jnk, order="AOE", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
p.mat = 1-abs(cor_jnk), sig.level=0.50, insig = "blank")
corrplot(cor_jnk, order = "hclust", addrect = 2)
corrplot(cor_jnk)
par(ask = TRUE)
corrplot(cor_jnk)
corrplot(cor_jnk, order = "hclust", addrect = 2)
corrplot(cor_jnk, order = "fpc", addrect = 2)
corrplot(cor_jnk, order = "FPC")
par(ask = FALSE)
corrplot(cor_jnk, order = "FPC")
corrplot(cor_jnk, method = "circle")
corrplot(cor_jnk, method = "pie")
corrplot(cor_jnk, method = "number")
corrplot(cor_jnk, method = "shade")
corrplot(cor_jnk, method = "color")
cor_jnk=cor(training[ ,-53])
plot(cor_jnk)
scatterplot.matrix(~., data=mtcars,
main="Three Cylinder Options")
scatterplot.matrix(~., data=cor_jnk,
main="Three Cylinder Options")
plot(cor_jnk)
pairs(cor_jnk)
pairs(cor_jnk)
pairs(cor_jnk)
par(mar = rep(2, 4))
pairs(cor_jnk)
cor_jnk=round(cor(training[ ,-53]),2)
cor_jnk=round(cor(training[ ,-53]),2)
cor_jnk
pairs(cor_jnk)
pairs(training)
corrplot(cor_jnk, method = "color")
library(reshape2)
melted_cormat <- melt(cor_jnk)
head(melted_cormat)
head(cor_jnk)
cor_train=round(cor(training[ ,-53]),2)
# Get upper triangle of the correlation matrix
get_upper_tri <- function(cor_train){
cor_train[lower.tri(cor_train)]<- NA
return(cor_train)
}
upper_tri <- get_upper_tri(cor_train)
upper_tri
library(reshape2)
melted_cor_train <- melt(upper_tri, na.rm = TRUE)
library(ggplot2)
ggplot(data = melted_cor_train, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
ggplot(data = melted_cor_train, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name="Pearson\nCorrelation") +
theme_minimal()+
theme(axis.text.x = element_text(angle = 90, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
install.packages("manipulate")
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
install.packages("rcharts")
install.packages("rCharts")
install.packages('base64enc')
install.packages("devtools")
library(rCharts)
library(devtools)
library(base64enc)
library(rCharts)
install_github('rCharts', 'ramnathv')
library(shiny)
library(devtools)
library(slidifyLibraries)
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runExample()
runExample("06_tabsets")
runExample("06_tabsets")
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runExample("04_mpg") # global variables
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runExample()
runExample("03_reactivity")
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runExample("03_reactivity")
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runExample()
runExample("07_widgets")
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
a=20
b <- as.character(ifelse(a < 25, "abc","xyz" ))
recommended<-as.data.frame(a,b)
recommended
recommended[1]
recommended<-as.data.frame(a,b,c)
employee <- c('John Doe','Peter Gynn','Jolie Hope')
salary <- c(21000, 23400, 26800)
employ.data <- data.frame(employee, salary)
str(employ.data)
employ.data
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
employ.data
row.names(employ.data)<-c("x", "y", "z")
employ.data
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
runApp('E:/COURSERA/DATA PRODUCT/CourseraProject')
shiny::runApp('E:/COURSERA/DATAPRODUCT/DataProductProjectApp')
library(devtools)
library(rsconnect)
getwd()
setwd("E:/COURSERA/DATAPRODUCT/DataProductProjectApp")
runApp()
devtools::install_github("rstudio/shinyapps")
runApp()
runApp()
library(rsconnect)
rsconnect::setAccountInfo(name='suparnasen',
token='AE2504AF339A1CF423BA92FC8BBC7249',
secret='<SECRET>')
rsconnect::setAccountInfo(name='suparnasen', token='AE2504AF339A1CF423BA92FC8BBC7249', secret='4Z8R6I1U/s8t7TwbeQDUR4uiwJO6erKaAYbovZda')
rsconnect::deployApp()
library(slidify)
library(slidifyLibraries)
author("mydeck")
library(slidify)
slidify("index.Rmd")
runDeck()
slidify("index.Rmd")
runDeck()
slidify("index.Rmd")
runDeck()
slidify("index.Rmd")
runDeck()
library(slidifyLibraries)
slidify("index.Rmd")
slidify("index.Rmd")
runDeck()
install_github('ramnathv/slidify', ref = github_pull(425))
library(slidifyLibraries)
library(slidify)
slidify("index.Rmd")
slidify("index.Rmd")
runDeck()
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
browseURL("index.html")
slidify("index.Rmd")
slidify("index.Rmd")
browseURL("index.html")
